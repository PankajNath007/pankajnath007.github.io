---
title: "Practical Machine Learning -Peer Assement "
author: "Pankaj"
date: "8 January 2017"
output: html_document
---
## Introduction  
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.  

In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise.  

## Data
The training data for this project are downloaded from: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are downloaded from: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. 

It is worth citing Groupware@LES for being generous in allowing their data to be used for this assignment.

## Goal of the assignment

1. Predicting the manner in which the participants did the exercise. Refer to the "classe" variable in the training set. All other variables can be used as predictor.

2. Show how the model was built, performed cross validation, and expectation of the sample error and reasons of choices made.

3. Use the prediction model to predict 20 different test cases.

## Data Preprocessing
```{r, echo=TRUE, results='hide', warning=FALSE, message=FALSE}
library(caret)
library(rpart)
library(knitr)
library(randomForest)
library(ElemStatLearn)
library(corrplot)
set.seed(888) # For research reproducibility purpose
```

## Download the Data
```{r downloadData }
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainFile <- "./data/pml-training.csv"
testFile  <- "./data/pml-testing.csv"
if (!file.exists("./data")) {
  dir.create("./data")
}
if (!file.exists(trainFile)) {
  download.file(trainUrl, destfile=trainFile)
}
if (!file.exists(testFile)) {
  download.file(testUrl, destfile=testFile)
}
```

### Read the Data
After downloading the data from the data source, the two csv files are read into two data frames.

```{r readData }
trainigFile_Data <- read.csv("./data/pml-training.csv",header=T,sep=",",na.strings=c("NA",""))
testFile_Data <- read.csv("./data/pml-testing.csv",header=T,sep=",",na.strings=c("NA",""))
dim(trainigFile_Data)
dim(testFile_Data)
```
The training data set contains 19622 observations and 160 variables, while the testing data set contains 20 observations and 160 variables. The "classe" variable in the training set is the outcome to predict.

### Cross Validation
Cross validation was achieved by splitting the training data into a test set and a training set using the following:
The data was partioned by the classe variable to ensure the training set and test set contain examples of each class. 60% of the training data was allocated to the training set and the remainder for the validation set.

```{r partionData}
trainigFile_Data <- trainigFile_Data[,-1] # Remove the first column that represents a ID Row
inTrain = createDataPartition(trainigFile_Data$classe, p=0.60, list=F)
training = trainigFile_Data[inTrain,]
validating = trainigFile_Data[-inTrain,]
```

### Data Cleaning
Since a random forest model is chosen and the data set must first be checked on possibility of columns without data.

The decision is made whereby all the columns that having less than 60% of data filled are removed.

```{r removeColumns}
sum((colSums(!is.na(training[,-ncol(training)])) < 0.6*nrow(training))) # Number of columns with less than 60% of data
```

Next, the criteria to remove columns that do not satisfy is applied before applying to the model.

```{r clean data}
Keep <- c((colSums(!is.na(training[,-ncol(training)])) >= 0.6*nrow(training)))
training   <-  training[,Keep]
validating <- validating[,Keep]
```

## Model Building
The training set needs to be large enough to achieve a relatively high accuracy, and the cross validation set also needs to be large enough to give a good indication of the out of sample error.

The training data set was split up into one portion (60%) for model building, and another portion (40%) for cross-validation, 

Random forest was chosen as the prediction algorithm used on the training dataset

```{r randomForest}
model <- randomForest(classe~.,data=training)
model
```

### Model Evaluation
Verification of the variable importance measures as produced by random Forest is as follows:
```{r impModel}
importance(model)
```
## Confusion Matrix

The confusion matrix allows visualization of the performance of an machine learning algorithm - typically a supervised learning. Each column of the matrix represents the instances in a predicted class, while each row represents the instances in an actual (reference) class.

```{r confusionmatrix }


  confusionMatrix(predict(model,newdata=validating[,-ncol(validating)]),validating$classe)


```

**The accurancy for the validating data set is calculated with the following formula:**

```{r accuracy_Calc }

  acrcy<-c(as.numeric(predict(model,newdata=validating[,-ncol(validating)])==validating$classe))
  acrcy<-sum(acrcy)*100/nrow(validating)

```

Model Accuracy as tested over Validation set = **`r acrcy`%**
The out-of-sample error is **0.13%**, which is pretty low.

## Model Test
For the model testing, the new values are predicted using the testing dataset provided which was loaded earlier. Data cleaning was first performed and  all columns of Testing data set are coerced for the same class of previous data set.

```{r modeltest}
  
  testFile_Data <- testFile_Data[,-1] # Remove the first column that represents a ID Row
  testFile_Data <- testFile_Data[ , Keep] # Keep the same columns of testing dataset
  testFile_Data <- testFile_Data[,-ncol(testFile_Data)] # Remove the problem ID
  
  
```

### Transformations and Coercing of Testing Dataset
```{r}
# Coerce testing dataset to same class and structure of training dataset 
testing <- rbind(training[100, -59] , testFile_Data) 

# Apply the ID Row to row.names and 100 for dummy row from testing dataset 
row.names(testing) <- c(100, 1:20)
```

### Prediction with the Testing Dataset
```{r}
predictions <- predict(model,newdata=testing[-1,])
predictions
```

## Generation of Answers Files for Assignment Submission
The following function pml_write_files is to create the answers files for the Prediction Assignment Submission:

```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("./problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictions)
```


